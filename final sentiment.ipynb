{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from translate import Translator\n",
    "import emoji\n",
    "import requests\n",
    "import datetime\n",
    "import goslate\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/project') \n",
    "\n",
    "#postgreSQLConnection = engine.connect()\n",
    "\n",
    "#connect to postgres\n",
    "\n",
    "#postgreSQLConnection.close();\n",
    "# #close connection to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>Fri May 07 05:47:05 +0000 2021</td>\n",
       "      <td>77.222178</td>\n",
       "      <td>28.632131</td>\n",
       "      <td>1.390544e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Why patents on COVID vaccines are so contentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>Fri May 07 09:02:35 +0000 2021</td>\n",
       "      <td>77.222178</td>\n",
       "      <td>28.632131</td>\n",
       "      <td>1.390593e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>COVID situation going from bad to worse; PM, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>Fri May 07 13:48:08 +0000 2021</td>\n",
       "      <td>77.222178</td>\n",
       "      <td>28.632131</td>\n",
       "      <td>1.390665e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Relaxing cap of Rs 2 lakh in cash transaction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>Sat May 08 13:27:03 +0000 2021</td>\n",
       "      <td>77.222178</td>\n",
       "      <td>28.632131</td>\n",
       "      <td>1.391022e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Eight COVID-19 survivors die of black fungus i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Mon May 10 02:18:37 +0000 2021</td>\n",
       "      <td>77.222178</td>\n",
       "      <td>28.632131</td>\n",
       "      <td>1.391578e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Rupee gains under siege as health crisis fuels...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at  longitude   latitude            id  \\\n",
       "3242  Fri May 07 05:47:05 +0000 2021  77.222178  28.632131  1.390544e+18   \n",
       "3243  Fri May 07 09:02:35 +0000 2021  77.222178  28.632131  1.390593e+18   \n",
       "3244  Fri May 07 13:48:08 +0000 2021  77.222178  28.632131  1.390665e+18   \n",
       "3245  Sat May 08 13:27:03 +0000 2021  77.222178  28.632131  1.391022e+18   \n",
       "3246  Mon May 10 02:18:37 +0000 2021  77.222178  28.632131  1.391578e+18   \n",
       "\n",
       "                 place                                               text  \n",
       "3242  New Delhi, India  Why patents on COVID vaccines are so contentio...  \n",
       "3243  New Delhi, India  COVID situation going from bad to worse; PM, h...  \n",
       "3244  New Delhi, India  Relaxing cap of Rs 2 lakh in cash transaction ...  \n",
       "3245  New Delhi, India  Eight COVID-19 survivors die of black fungus i...  \n",
       "3246  New Delhi, India  Rupee gains under siege as health crisis fuels...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading table from posgres pandas dataframe  \n",
    "df=pd.read_sql_query('select * from \"delhi_loc\"',con=engine)\n",
    "df = df.dropna(subset=['id','text','created_at','latitude','longitude'])\n",
    "df= df.reset_index()\n",
    "df.drop('index', axis = 1, inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arranging data frame by date and time\n",
    "date=[]\n",
    "time=[]\n",
    "for i in range(len(df)):\n",
    "    created_at=datetime.datetime.strptime(df['created_at'][i], \"%a %b %d %H:%M:%S +%f %Y\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    date.append(created_at.split(' ')[0])\n",
    "    time.append(created_at.split(' ')[1])\n",
    "    \n",
    "df[\"date\"] = date\n",
    "df[\"time\"] = time\n",
    "df=df.sort_values('date') \n",
    "df = df.reset_index()\n",
    "df.drop(['index','created_at'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-08-12', '06:04:07']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_at.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>demojized</th>\n",
       "      <th>text_eng</th>\n",
       "      <th>rm_puntu</th>\n",
       "      <th>...</th>\n",
       "      <th>Random_score</th>\n",
       "      <th>Random_sentiment</th>\n",
       "      <th>stoch_score</th>\n",
       "      <th>stoch_sentiment</th>\n",
       "      <th>NB_score</th>\n",
       "      <th>NB_sentiment</th>\n",
       "      <th>svc_rbf_score</th>\n",
       "      <th>svc_rbf_sentiment</th>\n",
       "      <th>svc_lin_score</th>\n",
       "      <th>svc_lin_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.251285</td>\n",
       "      <td>28.517921</td>\n",
       "      <td>1.241076e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>18:57:41</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>this guy alwayz charms with his monologue be i...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.219672</td>\n",
       "      <td>28.631747</td>\n",
       "      <td>1.241091e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Please follow janata curfew for betterment of ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>19:54:34</td>\n",
       "      <td>Please follow janata curfew for betterment of ...</td>\n",
       "      <td>Please follow janata curfew for betterment of ...</td>\n",
       "      <td>please follow janata curfew for betterment of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.219672</td>\n",
       "      <td>28.631747</td>\n",
       "      <td>1.241040e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>#StayHomeStaySafe\\nYou can avoid this virus. W...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>16:30:51</td>\n",
       "      <td>#StayHomeStaySafe\\nYou can avoid this virus. W...</td>\n",
       "      <td>#StayHomeStaySafe\\nYou can avoid this virus. W...</td>\n",
       "      <td>stayhomestaysafe you can avoid this virus  wa...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.219672</td>\n",
       "      <td>28.631747</td>\n",
       "      <td>1.240967e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>11:42:41</td>\n",
       "      <td>Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...</td>\n",
       "      <td>Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...</td>\n",
       "      <td>always with us                     make corona...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.047950</td>\n",
       "      <td>28.596764</td>\n",
       "      <td>1.240849e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>Those were the best days of my life \\nSuddenly...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:52:55</td>\n",
       "      <td>Those were the best days of my life \\nSuddenly...</td>\n",
       "      <td>Those were the best days of my life \\nSuddenly...</td>\n",
       "      <td>those were the best days of my life  suddenly ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude            id             place  \\\n",
       "0  77.251285  28.517921  1.241076e+18  New Delhi, India   \n",
       "1  77.219672  28.631747  1.241091e+18  New Delhi, India   \n",
       "2  77.219672  28.631747  1.241040e+18  New Delhi, India   \n",
       "3  77.219672  28.631747  1.240967e+18  New Delhi, India   \n",
       "4  77.047950  28.596764  1.240849e+18  New Delhi, India   \n",
       "\n",
       "                                                text        date      time  \\\n",
       "0  This guy alwayz charms with his monologue,be i...  2020-03-20  18:57:41   \n",
       "1  Please follow janata curfew for betterment of ...  2020-03-20  19:54:34   \n",
       "2  #StayHomeStaySafe\\nYou can avoid this virus. W...  2020-03-20  16:30:51   \n",
       "3  Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...  2020-03-20  11:42:41   \n",
       "4  Those were the best days of my life \\nSuddenly...  2020-03-20  03:52:55   \n",
       "\n",
       "                                           demojized  \\\n",
       "0  This guy alwayz charms with his monologue,be i...   \n",
       "1  Please follow janata curfew for betterment of ...   \n",
       "2  #StayHomeStaySafe\\nYou can avoid this virus. W...   \n",
       "3  Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...   \n",
       "4  Those were the best days of my life \\nSuddenly...   \n",
       "\n",
       "                                            text_eng  \\\n",
       "0  This guy alwayz charms with his monologue,be i...   \n",
       "1  Please follow janata curfew for betterment of ...   \n",
       "2  #StayHomeStaySafe\\nYou can avoid this virus. W...   \n",
       "3  Always with us í ¾í´í ¾í´í ½í±\\n\\nMake coro...   \n",
       "4  Those were the best days of my life \\nSuddenly...   \n",
       "\n",
       "                                            rm_puntu  ... Random_score  \\\n",
       "0  this guy alwayz charms with his monologue be i...  ...           -1   \n",
       "1  please follow janata curfew for betterment of ...  ...            0   \n",
       "2   stayhomestaysafe you can avoid this virus  wa...  ...            0   \n",
       "3  always with us                     make corona...  ...           -1   \n",
       "4  those were the best days of my life  suddenly ...  ...           -1   \n",
       "\n",
       "   Random_sentiment stoch_score  stoch_sentiment  NB_score NB_sentiment  \\\n",
       "0          Negative          -1         Negative        -1     Negative   \n",
       "1           Neutral           0          Neutral         0      Neutral   \n",
       "2           Neutral           0          Neutral         0      Neutral   \n",
       "3          Negative          -1         Negative        -1     Negative   \n",
       "4          Negative          -1         Negative        -1     Negative   \n",
       "\n",
       "   svc_rbf_score svc_rbf_sentiment  svc_lin_score svc_lin_sentiment  \n",
       "0             -1          Negative             -1          Negative  \n",
       "1              0           Neutral              0           Neutral  \n",
       "2              0           Neutral              0           Neutral  \n",
       "3             -1          Negative             -1          Negative  \n",
       "4             -1          Negative             -1          Negative  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing emoji's\n",
    "\n",
    "df['demojized']=\" \"\n",
    "\n",
    "demojized = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    text = df.loc[i,'text']\n",
    "    finalText = emoji.demojize(text,delimiters=(\"\", \" \")).replace('_',' ').replace('-',' ')\n",
    "    demojized.append(finalText)\n",
    "\n",
    "df['demojized'] = demojized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transulating all languages to english\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "fullText = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text = df.loc[i,'demojized']\n",
    "    lang = detect(text)\n",
    "    if lang!='en':\n",
    "        text = GoogleTranslator(source='auto', target='en').translate(text)        \n",
    "    fullText.append(text)\n",
    "\n",
    "df['text_eng'] = fullText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>demojized</th>\n",
       "      <th>text_eng</th>\n",
       "      <th>rm_puntu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.251285</td>\n",
       "      <td>28.517921</td>\n",
       "      <td>1.241076e+18</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>18:57:41</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>This guy alwayz charms with his monologue,be i...</td>\n",
       "      <td>this guy alwayz charms with his monologue be i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude            id             place  \\\n",
       "0  77.251285  28.517921  1.241076e+18  New Delhi, India   \n",
       "\n",
       "                                                text        date      time  \\\n",
       "0  This guy alwayz charms with his monologue,be i...  2020-03-20  18:57:41   \n",
       "\n",
       "                                           demojized  \\\n",
       "0  This guy alwayz charms with his monologue,be i...   \n",
       "\n",
       "                                            text_eng  \\\n",
       "0  This guy alwayz charms with his monologue,be i...   \n",
       "\n",
       "                                            rm_puntu  \n",
       "0  this guy alwayz charms with his monologue be i...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertng text to lower case\n",
    "\n",
    "df['rm_puntu']=df['text_eng'].str.lower()\n",
    "  \n",
    "#removing puntuations\n",
    "\n",
    "df['rm_puntu'].replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df['rm_puntu']\n",
    "\n",
    "stopwords = open(r\"C:\\Users\\HP\\Desktop\\sentiment\\stopwords.en.txt\", 'r' , encoding=\"ISO-8859-1\").read()\n",
    "stopwords = stopwords.split(\"\\n\")\n",
    "stopword_data=[]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    sentence=data[i]\n",
    "    sentencewords = sentence.split()\n",
    "    resultwords  = [word for word in sentencewords if word.lower() not in stopwords]\n",
    "    result = ' '.join(resultwords)\n",
    "    stopword_data.append(result)\n",
    "df['rm_stopword'] = stopword_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting to csv for doing traing\n",
    "df.to_csv(r\"C:\\Users\\HP\\Desktop\\sentiment\\delhi_loc_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#performing sentiment analysis by nltk\n",
    "\n",
    "from textblob import TextBlob as TB\n",
    "import pandas as pd\n",
    "\n",
    "score = []\n",
    "sentiment = []\n",
    "\n",
    "city_data = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\sentiment\\data\\labeled.csv\")\n",
    "for i in range(len(df)):\n",
    "    fullText = df.loc[i,'rm_stopword']\n",
    "    sentimentScore = TB(fullText).sentiment.polarity\n",
    "    sentimentScore = float(sentimentScore)\n",
    "    score.append(sentimentScore)\n",
    "    if (sentimentScore < 0.0):\n",
    "        sentiment.append('Negative')\n",
    "    elif (sentimentScore == 0.0):\n",
    "        sentiment.append('Neutral')\n",
    "    elif (sentimentScore > 0.0):\n",
    "        sentiment.append('Positive')\n",
    "\n",
    "df['textblob_Score'] = score\n",
    "df['textblob_Sentiment'] = sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exporting to csv for doing traing\n",
    "#df.to_csv(r\"C:\\Users\\HP\\Desktop\\sentiment\\delhi_textblob.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exporting data to postgres database\n",
    "#df.to_sql('delhi_cleaned_new',postgreSQLConnection,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>geom</th>\n",
       "      <th>demojized</th>\n",
       "      <th>text_eng</th>\n",
       "      <th>rm_puntu</th>\n",
       "      <th>rm_stopword</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>3242</td>\n",
       "      <td>11-08-2021 6.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.430000e+18</td>\n",
       "      <td>INGMT Ã¢ÂÂ Coronavirus likely to lock India'...</td>\n",
       "      <td>0101000020E6100000312BD2CCAC51534086421DB9E289...</td>\n",
       "      <td>INGMT Ã¢ÂÂ Coronavirus likely to lock India'...</td>\n",
       "      <td>INGMT Ã¢ÂÂ Coronavirus likely to lock India'...</td>\n",
       "      <td>ingmt     coronavirus likely to lock india s w...</td>\n",
       "      <td>ingmt coronavirus likely lock india women job ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>3243</td>\n",
       "      <td>11-08-2021 7.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.430000e+18</td>\n",
       "      <td>INGMT Ã¢ÂÂ India's gender inequity in vaccin...</td>\n",
       "      <td>0101000020E6100000312BD2CCAC51534086421DB9E289...</td>\n",
       "      <td>INGMT Ã¢ÂÂ India's gender inequity in vaccin...</td>\n",
       "      <td>INGMT Ã¢ÂÂ India's gender inequity in vaccin...</td>\n",
       "      <td>ingmt     india s gender inequity in vaccinati...</td>\n",
       "      <td>ingmt india gender inequity vaccinations narro...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>3244</td>\n",
       "      <td>11-08-2021 10.30</td>\n",
       "      <td>covaxin 1stdosedone vaccinationdone Ã¡Â´Â Ã¡Â´...</td>\n",
       "      <td>1.430000e+18</td>\n",
       "      <td>Finally I got my vaccine.\\n #covaxin\\n#1stdose...</td>\n",
       "      <td>0101000020E6100000FC7F07CCE44C5340873AE61B55A0...</td>\n",
       "      <td>Finally I got my vaccine.\\n #covaxin\\n#1stdose...</td>\n",
       "      <td>Finally I got my vaccine.\\n #covaxin\\n#1stdose...</td>\n",
       "      <td>finally i got my vaccine    covaxin   stdosedo...</td>\n",
       "      <td>finally got vaccine covaxin stdosedone vaccina...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>3245</td>\n",
       "      <td>11-08-2021 14.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.430000e+18</td>\n",
       "      <td>INNR Ã¢ÂÂ Government and people will work to...</td>\n",
       "      <td>0101000020E6100000749ECACC394C53403836960BF098...</td>\n",
       "      <td>INNR Ã¢ÂÂ Government and people will work to...</td>\n",
       "      <td>INNR Ã¢ÂÂ Government and people will work to...</td>\n",
       "      <td>innr     government and people will work toget...</td>\n",
       "      <td>innr government people work together make indi...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>3246</td>\n",
       "      <td>12-08-2021 6.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.430000e+18</td>\n",
       "      <td>INGMT Ã¢ÂÂ Government and people will work t...</td>\n",
       "      <td>0101000020E6100000312BD2CCAC51534086421DB9E289...</td>\n",
       "      <td>INGMT Ã¢ÂÂ Government and people will work t...</td>\n",
       "      <td>INGMT Ã¢ÂÂ Government and people will work t...</td>\n",
       "      <td>ingmt     government and people will work toge...</td>\n",
       "      <td>ingmt government people work together make ind...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        created_at  \\\n",
       "3242        3242   11-08-2021 6.04   \n",
       "3243        3243   11-08-2021 7.06   \n",
       "3244        3244  11-08-2021 10.30   \n",
       "3245        3245  11-08-2021 14.11   \n",
       "3246        3246   12-08-2021 6.04   \n",
       "\n",
       "                                               hashtags            id  \\\n",
       "3242                                                NaN  1.430000e+18   \n",
       "3243                                                NaN  1.430000e+18   \n",
       "3244  covaxin 1stdosedone vaccinationdone Ã¡Â´Â Ã¡Â´...  1.430000e+18   \n",
       "3245                                                NaN  1.430000e+18   \n",
       "3246                                                NaN  1.430000e+18   \n",
       "\n",
       "                                                   text  \\\n",
       "3242  INGMT Ã¢ÂÂ Coronavirus likely to lock India'...   \n",
       "3243  INGMT Ã¢ÂÂ India's gender inequity in vaccin...   \n",
       "3244  Finally I got my vaccine.\\n #covaxin\\n#1stdose...   \n",
       "3245  INNR Ã¢ÂÂ Government and people will work to...   \n",
       "3246  INGMT Ã¢ÂÂ Government and people will work t...   \n",
       "\n",
       "                                                   geom  \\\n",
       "3242  0101000020E6100000312BD2CCAC51534086421DB9E289...   \n",
       "3243  0101000020E6100000312BD2CCAC51534086421DB9E289...   \n",
       "3244  0101000020E6100000FC7F07CCE44C5340873AE61B55A0...   \n",
       "3245  0101000020E6100000749ECACC394C53403836960BF098...   \n",
       "3246  0101000020E6100000312BD2CCAC51534086421DB9E289...   \n",
       "\n",
       "                                              demojized  \\\n",
       "3242  INGMT Ã¢ÂÂ Coronavirus likely to lock India'...   \n",
       "3243  INGMT Ã¢ÂÂ India's gender inequity in vaccin...   \n",
       "3244  Finally I got my vaccine.\\n #covaxin\\n#1stdose...   \n",
       "3245  INNR Ã¢ÂÂ Government and people will work to...   \n",
       "3246  INGMT Ã¢ÂÂ Government and people will work t...   \n",
       "\n",
       "                                               text_eng  \\\n",
       "3242  INGMT Ã¢ÂÂ Coronavirus likely to lock India'...   \n",
       "3243  INGMT Ã¢ÂÂ India's gender inequity in vaccin...   \n",
       "3244  Finally I got my vaccine.\\n #covaxin\\n#1stdose...   \n",
       "3245  INNR Ã¢ÂÂ Government and people will work to...   \n",
       "3246  INGMT Ã¢ÂÂ Government and people will work t...   \n",
       "\n",
       "                                               rm_puntu  \\\n",
       "3242  ingmt     coronavirus likely to lock india s w...   \n",
       "3243  ingmt     india s gender inequity in vaccinati...   \n",
       "3244  finally i got my vaccine    covaxin   stdosedo...   \n",
       "3245  innr     government and people will work toget...   \n",
       "3246  ingmt     government and people will work toge...   \n",
       "\n",
       "                                            rm_stopword  Sentiment Score  \\\n",
       "3242  ingmt coronavirus likely lock india women job ...         0.100000   \n",
       "3243  ingmt india gender inequity vaccinations narro...         0.333333   \n",
       "3244  finally got vaccine covaxin stdosedone vaccina...         0.068182   \n",
       "3245  innr government people work together make indi...         0.133333   \n",
       "3246  ingmt government people work together make ind...         0.133333   \n",
       "\n",
       "     Sentiment  label  \n",
       "3242  Positive      1  \n",
       "3243  Positive      1  \n",
       "3244  Positive      1  \n",
       "3245  Positive      1  \n",
       "3246  Positive      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the trainig and testing data\n",
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\HP\\Desktop\\sentiment\\delhi_train_trial.csv\", encoding = \"ISO-8859-1\")\n",
    "data.head()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add label to data base \n",
    "\n",
    "df['label'] = data.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1      0\n",
       "2      0\n",
       "3     -1\n",
       "4     -1\n",
       "      ..\n",
       "795    0\n",
       "796    1\n",
       "797    1\n",
       "798    0\n",
       "799    0\n",
       "Name: label, Length: 800, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.iloc[0:3000,9]\n",
    "train_label = data.iloc[0:3000,12]\n",
    "test = data.iloc[3000:3247,9]\n",
    "test_label = data.iloc[3000:3247,12]\n",
    "\n",
    "train_label.head(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# implement BAG OF WORDS by using count vector using bigram method\n",
    "\n",
    "countvector=CountVectorizer(ngram_range=(1,2))\n",
    "train_countV=countvector.fit_transform(train)\n",
    "test_countV = countvector.transform(test)\n",
    "data_count = countvector.transform(data.iloc[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implement BAG OF WORDS by using TFIDF process\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer \n",
    "# transformer = TfidfTransformer()\n",
    "# train_TFIDF = transformer.fit(train)\n",
    "# test_TFIDF = transformer.fit(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding parameters for RandomForest Classifier\n",
    "\n",
    "def classification_params(test,predic):\n",
    "\n",
    "    from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "    \n",
    "    matrix=confusion_matrix(test,predic)\n",
    "    print(matrix)\n",
    "    score=accuracy_score(test,predic)\n",
    "    print(score)\n",
    "    report=classification_report(test,predic)\n",
    "    print(report)\n",
    "    return matrix, score, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(score):\n",
    "    sentiment = []\n",
    "    for i in range(len(df)):\n",
    "        sentimentScore = df.loc[i,score]\n",
    "        if (sentimentScore < 0.0):\n",
    "            sentiment.append('Negative')\n",
    "        elif (sentimentScore == 0.0):\n",
    "            sentiment.append('Neutral')\n",
    "        elif (sentimentScore > 0.0):\n",
    "            sentiment.append('Positive')\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#implement RandomForest Classifier for count vector\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(train_countV,train_label)\n",
    "\n",
    "random_count_pred = randomclassifier.predict(test_countV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Pred_data = randomclassifier.predict(data_count)\n",
    "\n",
    "df['Random_score'] = Random_Pred_data\n",
    "\n",
    "df['Random_sentiment'] = sentiment('Random_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  25   7]\n",
      " [  0 128   9]\n",
      " [  0  19  48]]\n",
      "0.757085020242915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.26      0.41        43\n",
      "           0       0.74      0.93      0.83       137\n",
      "           1       0.75      0.72      0.73        67\n",
      "\n",
      "    accuracy                           0.76       247\n",
      "   macro avg       0.83      0.64      0.66       247\n",
      "weighted avg       0.79      0.76      0.73       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_params(test_label,random_count_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  9  4]\n",
      " [22 95 20]\n",
      " [ 5 11 51]]\n",
      "0.7125506072874493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.70      0.60        43\n",
      "           0       0.83      0.69      0.75       137\n",
      "           1       0.68      0.76      0.72        67\n",
      "\n",
      "    accuracy                           0.71       247\n",
      "   macro avg       0.68      0.72      0.69       247\n",
      "weighted avg       0.73      0.71      0.72       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#implementing STOCHASTIC_DESCENT algorithm\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "stoch = SGDClassifier(loss=\"hinge\", penalty=\"l1\", max_iter=1000)\n",
    "\n",
    "stoch.fit(train_countV, train_label)\n",
    "\n",
    "stoch_count_pred = stoch.predict(test_countV)\n",
    "\n",
    "classification_params(test_label,stoch_count_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stoch_pred_data = stoch.predict(data_count)\n",
    "\n",
    "df['stoch_score'] = stoch_pred_data\n",
    "\n",
    "df['stoch_sentiment'] = sentiment('stoch_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5  31   7]\n",
      " [  0 115  22]\n",
      " [  2  19  46]]\n",
      "0.6720647773279352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.12      0.20        43\n",
      "           0       0.70      0.84      0.76       137\n",
      "           1       0.61      0.69      0.65        67\n",
      "\n",
      "    accuracy                           0.67       247\n",
      "   macro avg       0.67      0.55      0.54       247\n",
      "weighted avg       0.68      0.67      0.63       247\n",
      "\n",
      "[[  9  28   6]\n",
      " [  0 129   8]\n",
      " [  0  33  34]]\n",
      "0.6963562753036437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.21      0.35        43\n",
      "           0       0.68      0.94      0.79       137\n",
      "           1       0.71      0.51      0.59        67\n",
      "\n",
      "    accuracy                           0.70       247\n",
      "   macro avg       0.80      0.55      0.58       247\n",
      "weighted avg       0.74      0.70      0.66       247\n",
      "\n",
      "[[ 17  22   4]\n",
      " [  7 122   8]\n",
      " [  3  20  44]]\n",
      "0.7408906882591093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.40      0.49        43\n",
      "           0       0.74      0.89      0.81       137\n",
      "           1       0.79      0.66      0.72        67\n",
      "\n",
      "    accuracy                           0.74       247\n",
      "   macro avg       0.72      0.65      0.67       247\n",
      "weighted avg       0.74      0.74      0.73       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# Perform classification with MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_countV, train_label)\n",
    "prediction_NB = clf.predict(test_countV)\n",
    "\n",
    "classification_params(test_label,prediction_NB)\n",
    "\n",
    "# Perform classification with SVM, kernel=rbf\n",
    "classifier_rbf = svm.SVC()\n",
    "classifier_rbf.fit(train_countV, train_label)\n",
    "prediction_rbf = classifier_rbf.predict(test_countV)\n",
    "\n",
    "classification_params(test_label,prediction_rbf)\n",
    "    \n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(train_countV, train_label)\n",
    "prediction_linear = classifier_linear.predict(test_countV)\n",
    "\n",
    "classification_params(test_label,prediction_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NB_score'] = clf.predict(data_count)\n",
    "\n",
    "df['NB_sentiment'] = sentiment('NB_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['svc_rbf_score'] = classifier_rbf.predict(data_count)\n",
    "\n",
    "df['svc_rbf_sentiment'] = sentiment('svc_rbf_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['svc_lin_score'] = classifier_linear.predict(data_count)\n",
    "\n",
    "df['svc_lin_sentiment'] = sentiment('svc_lin_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#connect to postgres\n",
    "\n",
    "postgreSQLConnection = engine.connect()\n",
    "\n",
    "#exporting data to postgres database\n",
    "df.to_sql('delhi_loc_machine',postgreSQLConnection,if_exists='replace')\n",
    "\n",
    "postgreSQLConnection.close();\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "234add224a49453f14ca85c5a2b4bc3db3f703c851e7b7dcb1c661491c6686f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
